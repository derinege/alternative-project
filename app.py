import os
import time
import threading
import requests
import json
import numpy as np
import re
from flask import Flask, render_template
from flask_socketio import SocketIO, emit
import speech_recognition as sr
from faster_whisper import WhisperModel
import pyaudio
import wave
import io
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from scipy.signal import spectrogram
import datetime

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key'
socketio = SocketIO(app, cors_allowed_origins="*")

# Global variables
is_listening = False
recognizer = sr.Recognizer()
transcript_text = ""
target_language = "en"
translation_service = "ollama"

# Whisper model y√ºkle (iPhone 14 Pro i√ßin optimize edilmi≈ü)
print("ü§ñ Whisper modeli y√ºkleniyor...")
whisper_model = WhisperModel("base", device="cpu", compute_type="int8")
print("‚úÖ Whisper modeli hazƒ±r! (iPhone 14 Pro i√ßin optimize edildi)")

# Ses analizi fonksiyonu
def analyze_audio(audio_data):
    """Ses sinyalini analiz et"""
    try:
        # Audio data'yƒ± numpy array'e √ßevir
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        
        # Temel istatistikler
        rms = float(np.sqrt(np.mean(audio_array**2)))
        peak = float(np.max(np.abs(audio_array)))
        dynamic_range = float(peak / (rms + 1e-10))
        
        # Frekans analizi (basit)
        fft = np.fft.fft(audio_array)
        freqs = np.fft.fftfreq(len(audio_array), 1/16000)
        dominant_freq = float(abs(freqs[np.argmax(np.abs(fft))]))
        
        # SNR hesapla (basit)
        signal_power = float(np.mean(audio_array**2))
        noise_floor = float(np.percentile(audio_array**2, 10))
        # SNR hesaplamasƒ± g√ºvenli hale getir
        if noise_floor < 1e-6:
            snr = float('nan')
        else:
            snr = float(10 * np.log10(signal_power / (noise_floor + 1e-10)))
        
        return {
            'rms': rms,
            'peak': peak,
            'dynamic_range': dynamic_range,
            'dominant_freq': dominant_freq,
            'snr': snr,
            'length_ms': float(len(audio_array) / 16)  # 16kHz sample rate
        }
    except Exception as e:
        print(f"‚ùå Ses analizi hatasƒ±: {e}")
        return None

def analyze_and_plot_audio(audio_data):
    """Ses sinyalini analiz et ve plot olarak kaydet"""
    try:
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        # Ba≈ülangƒ±√ß spike'ƒ±nƒ± atla (ilk 1000 sample)
        if len(audio_array) > 1000:
            audio_array = audio_array[1000:]
        rms = float(np.sqrt(np.mean(audio_array**2)))
        peak = float(np.max(np.abs(audio_array)))
        dynamic_range = float(peak / (rms + 1e-10))
        fft = np.fft.fft(audio_array)
        freqs = np.fft.fftfreq(len(audio_array), 1/16000)
        dominant_freq = float(abs(freqs[np.argmax(np.abs(fft))]))
        signal_power = float(np.mean(audio_array**2))
        noise_floor = float(np.percentile(audio_array**2, 10))
        snr = float('nan') if noise_floor < 1e-6 else 10 * np.log10(signal_power / (noise_floor + 1e-10))
        # dB hesapla (referans: 32767)
        db = 20 * np.log10(rms / 32767 + 1e-10)
        # Plot ve kaydet
        ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        plt.figure(figsize=(10, 2))
        plt.plot(audio_array)
        plt.title('Audio Waveform')
        plt.xlabel('Sample')
        plt.ylabel('Amplitude')
        plt.tight_layout()
        plt.savefig(f'audio_waveform_{ts}.png')
        print(f'[AUDIO] Waveform plot saved: audio_waveform_{ts}.png')
        plt.close()
        # Spectrogram
        f, t, Sxx = spectrogram(audio_array, fs=16000)
        plt.figure(figsize=(10,4))
        plt.pcolormesh(t, f, 10*np.log10(Sxx+1e-10), shading='gouraud')
        plt.ylabel('Frequency [Hz]')
        plt.xlabel('Time [sec]')
        plt.title('Spectrogram')
        plt.colorbar(label='dB')
        plt.tight_layout()
        plt.savefig(f'audio_spectrogram_{ts}.png')
        print(f'[AUDIO] Spectrogram plot saved: audio_spectrogram_{ts}.png')
        plt.close()
        return {
            'rms': rms,
            'peak': peak,
            'snr': snr,
            'dominant_freq': dominant_freq,
            'db': db
        }
    except Exception as e:
        print(f'[AUDIO] Analysis error: {e}')
        return {}

# √áeviri cache'i - aynƒ± kelimeleri tekrar √ßevirmemek i√ßin
translation_cache = {}

# C√ºmle algƒ±lama fonksiyonu
def detect_sentences(text):
    """Metni c√ºmlelere ayƒ±rƒ±r ve noktalama i≈üaretlerini d√ºzeltir"""
    # C√ºmle sonu i≈üaretlerini ekle
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    # Son c√ºmleyi tamamla
    if text and not text[-1] in '.!?':
        if sentences:
            sentences[-1] = sentences[-1] + '.'
    
    return sentences

# Ollama ile hƒ±zlƒ± √ßeviri
def translate_ollama(text, target_lang):
    """Ollama ile local √ßeviri - √ßok hƒ±zlƒ±"""
    try:
        # Cache kontrol√º
        cache_key = f"{text}_{target_lang}"
        if cache_key in translation_cache:
            return translation_cache[cache_key]
        
        # Dil kodlarƒ±nƒ± √ßevir
        lang_map = {
            'en': 'English',
            'es': 'Spanish', 
            'fr': 'French',
            'de': 'German',
            'it': 'Italian',
            'pt': 'Portuguese',
            'ru': 'Russian',
            'ja': 'Japanese',
            'ko': 'Korean',
            'zh': 'Chinese',
            'ar': 'Arabic'
        }
        
        target_lang_name = lang_map.get(target_lang, 'English')
        
        # Ollama prompt'u
        prompt = f"""Translate this Turkish text to {target_lang_name}. Only return the translation, nothing else:

Turkish: {text}
{target_lang_name}:"""
        
        # Ollama ile √ßeviri
        response = requests.post("http://localhost:11434/api/generate", json={
            "model": "llama3.2:1b",  # iPhone i√ßin daha hafif model
            "prompt": prompt,
            "stream": False
        }, timeout=10)
        
        if response.status_code == 200:
            result = response.json()
            translated = result.get('response', '').strip()
            
            # Cache'e kaydet
            translation_cache[cache_key] = translated
            
            return translated
        else:
            return f"√áeviri hatasƒ±: HTTP {response.status_code}"
        
    except Exception as e:
        print(f"Ollama √ßeviri hatasƒ±: {e}")
        return f"√áeviri hatasƒ±: {str(e)}"

# Google Translate API (fallback)
def translate_google(text, target_lang):
    """Google Translate ile √ßeviri (fallback)"""
    try:
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            'client': 'gtx',
            'sl': 'tr',  # Kaynak dil: T√ºrk√ße
            'tl': target_lang,  # Hedef dil
            'dt': 't',
            'q': text
        }
        response = requests.get(url, params=params)
        if response.status_code == 200:
            result = response.json()
            translated_text = ''.join([part[0] for part in result[0] if part[0]])
            return translated_text
        else:
            return f"√áeviri hatasƒ±: {response.status_code}"
    except Exception as e:
        return f"√áeviri hatasƒ±: {str(e)}"

# Hƒ±zlƒ± √ßeviri fonksiyonu
def translate_realtime(text, target_lang, service):
    """Ger√ßek zamanlƒ± √ßeviri - √ßok hƒ±zlƒ±"""
    try:
        if service == 'ollama':
            return translate_ollama(text, target_lang)
        elif service == 'google':
            return translate_google(text, target_lang)
        else:
            return "Desteklenmeyen √ßeviri servisi"
    except Exception as e:
        return f"√áeviri hatasƒ±: {str(e)}"

def translate_text(text, target_lang, service):
    """Metni √ßevir ve frontend'e g√∂nder"""
    try:
        start_time = time.time()
        
        if service == "ollama":
            translated = translate_ollama(text, target_lang)
        else:
            translated = translate_google(text, target_lang)
        
        duration = (time.time() - start_time) * 1000  # ms cinsinden
        print(f"üåê √áeviri: {translated} (S√ºre: {duration:.0f} ms)")
        
        # JSON serializable data g√∂nder
        socketio.emit('translation_result', {
            'translated_text': translated,
            'duration': duration / 1000.0  # saniye cinsinden
        })
        
    except Exception as e:
        print(f"‚ùå √áeviri hatasƒ±: {e}")

def translate_with_ollama(text, target_lang):
    """Ollama ile √ßeviri"""
    try:
        # Ollama API endpoint
        url = "http://localhost:11434/api/generate"
        
        # Dil kodlarƒ±nƒ± Ollama formatƒ±na √ßevir
        lang_map = {
            "en": "English",
            "es": "Spanish", 
            "fr": "French",
            "de": "German",
            "it": "Italian",
            "pt": "Portuguese",
            "ru": "Russian",
            "ja": "Japanese",
            "ko": "Korean",
            "zh": "Chinese"
        }
        
        target_lang_name = lang_map.get(target_lang, "English")
        
        prompt = f"Translate the following Turkish text to {target_lang_name}. Only provide the translation, nothing else:\n\n{text}"
        
        data = {
            "model": "llama3.2:1b",  # iPhone i√ßin daha hafif model
            "prompt": prompt,
            "stream": False
        }
        
        response = requests.post(url, json=data, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        translated = result.get('response', '').strip()
        
        return translated
        
    except Exception as e:
        print(f"‚ùå Ollama √ßeviri hatasƒ±: {e}")
        return f"[√áeviri hatasƒ±: {e}]"

def translate_with_google(text, target_lang):
    """Google Translate ile √ßeviri (fallback)"""
    try:
        # Basit Google Translate API sim√ºlasyonu
        # Ger√ßek uygulamada Google Translate API kullanƒ±labilir
        return f"[Google: {text}]"
    except Exception as e:
        print(f"‚ùå Google √ßeviri hatasƒ±: {e}")
        return f"[√áeviri hatasƒ±: {e}]"

# Mikrofonlarƒ± listele
@socketio.on('get_microphones')
def handle_get_microphones():
    try:
        mic_list = sr.Microphone.list_microphone_names()
        # Aktif mikrofon index'i (varsayƒ±lan 0)
        default_index = 0
        socketio.emit('microphone_list', {
            'microphones': [
                {'index': i, 'name': name} for i, name in enumerate(mic_list)
            ],
            'default_index': default_index
        })
    except Exception as e:
        socketio.emit('microphone_list', {'microphones': [], 'default_index': 0, 'error': str(e)})

def listen_and_transcribe():
    global is_listening, transcript_text
    with sr.Microphone() as source:
        recognizer.adjust_for_ambient_noise(source, duration=0.3)
        print("üé§ Sistem hazƒ±r. Dinleme ba≈ülatƒ±lmayƒ± bekliyor...")
        
        while True:
            if is_listening:
                try:
                    print("üé§ Dinleniyor...")
                    audio_start_time = time.time()
                    
                    # iPhone 14 Pro i√ßin optimize edilmi≈ü audio kayƒ±t parametreleri
                    audio = recognizer.listen(
                        source, 
                        timeout=3.0,  # iPhone i√ßin daha kƒ±sa timeout
                        phrase_time_limit=3.0  # iPhone i√ßin daha kƒ±sa phrase limit
                    )
                    audio_data = audio.get_raw_data()
                    
                    # Sinyal analizi ve dB hesapla
                    features = analyze_and_plot_audio(audio_data)
                    
                    # dB seviyesini frontend'e g√∂nder
                    socketio.emit('audio_features', {'db': features.get('db', None)})
                    
                    # WAV buffer olu≈ütur
                    wav_buffer = io.BytesIO()
                    with wave.open(wav_buffer, 'wb') as wf:
                        wf.setnchannels(1)
                        wf.setsampwidth(2)
                        wf.setframerate(16000)
                        wf.writeframes(audio_data)
                    wav_buffer.seek(0)
                    
                    # Whisper ile transcribe
                    print("üîÑ Whisper ile i≈üleniyor...")
                    stt_start = time.time()
                    # iPhone 14 Pro i√ßin optimize edilmi≈ü Whisper parametreleri
                    segments, info = whisper_model.transcribe(
                        wav_buffer,
                        beam_size=1,  # En hƒ±zlƒ±
                        temperature=0.0,  # Deterministik
                        log_prob_threshold=-1.0,
                        no_speech_threshold=0.4,  # iPhone i√ßin biraz daha hassas
                        language="tr",  # T√ºrk√ße zorlamasƒ±
                        condition_on_previous_text=False,  # Hƒ±z i√ßin
                        initial_prompt="A≈üaƒüƒ±daki T√ºrk√ße konu≈ümayƒ± doƒüru ve eksiksiz yazƒ±ya d√∂k. Kƒ±saltma, atlama veya deƒüi≈ütirme yapma. Sadece konu≈üulanƒ± yaz.",
                        word_timestamps=False,  # Hƒ±z i√ßin
                        max_initial_timestamp=0.5,  # iPhone i√ßin daha kƒ±sa
                        max_new_tokens=32  # iPhone i√ßin daha kƒ±sa √ßƒ±ktƒ±
                    )
                    stt_end = time.time()
                    
                    # Segmentleri birle≈ütir
                    text = ""
                    for segment in segments:
                        text += segment.text + " "
                    
                    text = text.strip()
                    
                    if text:
                        stt_duration = (stt_end - stt_start) * 1000  # ms cinsinden
                        print(f"üìù Whisper: {text} (S√ºre: {stt_duration:.0f} ms)")
                        
                        # Algƒ±lanan dili belirle
                        detected_lang = "tr"  # T√ºrk√ße zorlamasƒ±
                        
                        # Frontend'e g√∂nder - JSON serializable data
                        socketio.emit('new_text', {
                            'text': text,
                            'stt_duration': stt_duration / 1000.0,  # saniye cinsinden
                            'lang': detected_lang
                        })
                        
                        # Dil algƒ±lama bilgisini g√∂nder
                        if detected_lang:
                            socketio.emit('detected_language', {
                                'lang': detected_lang
                            })
                        
                        # √áeviri yap
                        if target_language and translation_service:
                            translate_text(text, target_language, translation_service)
                    
                except sr.WaitTimeoutError:
                    print("‚è∞ Dinleme zaman a≈üƒ±mƒ±")
                except Exception as e:
                    print(f"Dinleme/Transkripsiyon hatasƒ±: {e}")
                    continue
            else:
                time.sleep(0.1)

@app.route('/')
def index():
    return render_template('index.html')

@socketio.on('connect')
def handle_connect():
    print("üåê Yeni baƒülantƒ± ba≈üarƒ±lƒ±")

@socketio.on('disconnect')
def handle_disconnect():
    print("‚ùå Baƒülantƒ± kesildi")

@socketio.on('start_listening')
def handle_start_listening(data):
    global is_listening, target_language, translation_service
    is_listening = True
    target_language = data.get('target_lang', 'en')
    translation_service = data.get('service', 'ollama')
    print(f"üé§ Dinleme ba≈ülatƒ±ldƒ± - Hedef dil: {target_language}, Servis: {translation_service}")
    socketio.emit('listening_started')

@socketio.on('stop_listening')
def handle_stop_listening():
    global is_listening, transcript_text
    is_listening = False
    print("‚èπÔ∏è Dinleme durduruldu")
    print(f"üìÑ Tam transkript: {transcript_text}")
    socketio.emit('listening_stopped')

# Background thread ba≈ülat
threading.Thread(target=listen_and_transcribe, daemon=True).start()

if __name__ == '__main__':
    # Arka planda konu≈üma tanƒ±ma thread'i ba≈ülat
    # t = threading.Thread(target=recognize_speech_background, daemon=True)
    # t.start()
    print("üöÄ Sunucu ba≈ülatƒ±lƒ±yor... http://localhost:3000")
    print("‚ö° Ollama ile hƒ±zlƒ± √ßeviri aktif!")
    # Flask-SocketIO sunucusunu ba≈ülat
    socketio.run(app, host='0.0.0.0', port=3000, debug=False) 